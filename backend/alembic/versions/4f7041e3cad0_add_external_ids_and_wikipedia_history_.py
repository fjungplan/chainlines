"""Add external_ids and wikipedia_history_content

Revision ID: 4f7041e3cad0
Revises: bb50b382938a
Create Date: 2026-01-06 15:26:21.000151

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '4f7041e3cad0'
down_revision: Union[str, None] = 'bb50b382938a'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Apply database schema changes."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_staging_source', table_name='scraped_data_staging')
    op.drop_index('idx_staging_status', table_name='scraped_data_staging')
    op.drop_table('scraped_data_staging')
    op.add_column('team_era', sa.Column('wikipedia_history_content', sa.Text(), nullable=True, comment='Cached Wikipedia History section text'))
    op.drop_column('team_era', 'external_ids')
    op.add_column('team_node', sa.Column('external_ids', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='External source IDs: {wikidata: Q123, ...}'))
    # ### end Alembic commands ###


def downgrade() -> None:
    """Revert database schema changes.
    
    WARNING: Make sure this migration is reversible!
    Consider data loss implications before rolling back.
    """
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('team_node', 'external_ids')
    op.add_column('team_era', sa.Column('external_ids', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.drop_column('team_era', 'wikipedia_history_content')
    op.create_table('scraped_data_staging',
    sa.Column('staging_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('source', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('source_url', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('source_id', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('scraped_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('raw_json', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('team_name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('season_year', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('tier', sa.VARCHAR(length=10), autoincrement=False, nullable=True),
    sa.Column('uci_code', sa.VARCHAR(length=3), autoincrement=False, nullable=True),
    sa.Column('sponsor_names', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=20), autoincrement=False, nullable=False),
    sa.Column('matched_team_era_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('confidence_score', sa.NUMERIC(precision=3, scale=2), autoincrement=False, nullable=True),
    sa.Column('processed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('processing_notes', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_audit_ids', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['matched_team_era_id'], ['team_era.era_id'], name='scraped_data_staging_matched_team_era_id_fkey', ondelete='SET NULL'),
    sa.PrimaryKeyConstraint('staging_id', name='scraped_data_staging_pkey'),
    sa.UniqueConstraint('source', 'source_id', 'season_year', name='uq_staging_source_season')
    )
    op.create_index('idx_staging_status', 'scraped_data_staging', ['status'], unique=False)
    op.create_index('idx_staging_source', 'scraped_data_staging', ['source', 'source_id'], unique=False)
    # ### end Alembic commands ###
